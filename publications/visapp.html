<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Best View Selection – VISAPP 2024</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" href="../graphics/favicon.ico"> 
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
  <!-- <link rel="stylesheet" type="text/css" href="../stylesheet.css" /> -->
  <link  rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" />
  <link rel="stylesheet" href="../graphics/icons/academicons-1.9.4/css/academicons.min.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <style>
    body { font-family: 'Arial', sans-serif; }
    .jumbotron { padding: 4rem 2rem; background-color: #f8f9fa; }
    .nav-pills img { transition: opacity 0.2s ease-in-out; }
    .hover-image-link:hover .first-image { display: none; }
    .hover-image-link:hover .second-image { display: inline; }
    .hover-image-link .second-image { display: none; }
    .img-responsive { max-width: 100%; height: auto; }
    .copy-button {
      padding: 10px 20px; font-size: 1rem;
      background-color: #007bff; color: white;
      border: none; border-radius: 5px; cursor: pointer;
    }
    .copy-button:hover { background-color: #0056b3; }
    #citation { font-family: monospace; background: #eee; padding: 10px; border-radius: 5px; }
  </style>

</head>
<body>

<!-- Banner Section -->
<section class="jumbotron text-center" id="banner">
  <div class="container">
    <h2 class="jumbotron-heading">Most Relevant Viewpoint of an Object: <br />a View-Dependent 3D Saliency Approach</h2>

    <div class="row justify-content-center mt-4">
      <div class="col-md-10">
        <p><strong>Marie Pelissier-Combescure</strong>, Sylvie Chambon, Géraldine Morin</p>
        <p>IRIT, University of Toulouse, France</p>
        <p style="color:red;"><strong>VISAPP International Conference on Computer Vision Theory and Applications</em></strong>, 2024, Rome, Italy</p>
      </div>
    </div>

<div class="row justify-content-center mt-4">
  <ul class="nav nav-pills justify-content-center text-center" style="width:100%;">
    <li class="nav-item" style="display:inline-block; margin:0 30px;">
      <img class="first-image" src="../graphics/visapp/pipeline_general.png" height="220px"> 
      <br /><br />
      <a href="https://hal.science/hal-05007308" target="_blank" rel="noopener noreferrer" style="text-decoration: none">
        <i class="ai ai-hal" style="font-size: 1.5em; vertical-align: middle; margin-right: 0.3em;"></i>Paper</a>
      </a>
    </li>
  </ul>
</div>
</section>

<!-- Abstract -->
<div class="container mt-5 text-center">
<h4 class="text-center"><strong>Abstract</strong></h4>
<p></p>
<p style="text-align: justify; max-width: 900px; margin: 0 auto;">
  A viewpoint of a 3D object is the position from which we observe the object. 
  A viewpoint always highlights some 3D parts and discards other parts of an object. 
  Here, we define a good viewpoint as offering a relevant view of the object: a view that best showcases the object and that is the most representative of the object. 
  Best view selection plays an essential role in many computer vision and virtual reality applications. 
  In this paper, given a model and a particular viewpoint, we want to quantify its relevance -not aesthetics. 
  We propose a geometric method for selecting the most relevant viewpoint for a 3D object by combining visibility and view-dependent saliency.
  Evaluating the quality of an estimated best viewpoint is a challenge.
  Thus, we propose an evaluation protocol that considers two different and complementary solutions: a user study with more than 200 participants to collect human preferences and an analysis of image dataset picturing objects of interest. 
  This evaluation highlights the correlation between our method and human preferences. 
  A quantitative comparison demonstrates the efficiency of our approach over reference methods.
  </p>
</div>

<!-- Overview Figure -->
<div class="container mt-5 text-center">
<h4 class="text-center"><strong>Point of View Scoring</strong></h4>
  <div class="text-center my-4">

    <img src="../graphics/visapp/pipeline.png"  height="350px" >
  </div>
  <p style="text-align: justify; max-width: 900px; margin: 0 auto;">
    We propose a relevance measure to automatically select the best viewpoint of a 3D object based on view-dependent 3D saliency.
    The score for a particular viewpoint (<em>pov</em>) is defined as: </p>
  <p> <br /><strong>Score(pov) = S(pov) + Se(pov) + Sa(pov)</strong>  </p>

  <p style="text-align: justify; max-width: 900px; margin: 0 auto;"><strong>Score Parameters:</strong></p>
  <p style="text-align: justify; max-width: 900px; margin: 0 auto;">
  Visibility S(pov): Quantifies the proportion of the model’s total 3D surface visible from the given viewpoint. It is computed as the ratio of the visible 3D surface to the total 3D surface.  </p>
  <br />
  <p style="text-align: justify; max-width: 900px; margin: 0 auto;">
  Eye Surface Visibility Se(pov): Measures the visibility of the eye surface (if present) from the given viewpoint. It is the ratio of the visible 3D surface of the eyes to their total surface.</p>
  <br />
  <p style="text-align: justify; max-width: 900px; margin: 0 auto;">
  Saliency of Visible Vertices Sa(pov): Represents the view-dependent 3D saliency of visible vertices.
  Computed as the sum of saliency values Si(v) of visible vertices, weighted by an angle-based function f(αv):<br></p>
  <code>Sa(pov) = ∑ Si(v) · f(αv), for all v ∈ V</code><br>
  where V is the set of visible vertices from viewpoint pov.

  <p style="text-align: justify; max-width: 900px; margin: 0 auto;"><strong>Saliency Parameters:</strong></p>
  <p style="text-align: justify; max-width: 900px; margin: 0 auto;">
  Intrinsic Saliency Method (Si):</strong> Five different methods were tested, including those by Lee (2005), Song (2014), Tasse (2015), Leifman (2016), and Limper (2016). Limper’s entropy-based multi-scale method gave the best results.</p>
  <br />
  <p style="text-align: justify; max-width: 900px; margin: 0 auto;">
  Angle Function (f):</strong> Five tested functions: cos(αv), √cos(αv), 1−cos(αv), 1−√cos(αv), and 0.5 + (1−√cos(αv))/2. The cosine function was most effective for prioritizing vertices facing the camera. Others that highlight contours may favor accidental views. </p>
  </ul>
  </p>
</div>

<!-- Interactive Results - Updated for OBJ loading -->
<div class="container mt-5 text-center">
  <h4 class="text-center"><strong>3D Model Viewer</strong></h4>
  <p>Click a button to load a different 3D object:</p>

  <div class="row justify-content-center g-4">
    <!-- Pair 1 -->
    <div class="col-md-3">
        <button class="btn btn-primary w-100" onclick="loadModel('../data/model_a.obj')">A</button>
        <button class="btn btn-primary w-100" onclick="loadModel('../data/model_b.obj')">B</button>
        <button class="btn btn-primary w-100" onclick="loadModel('../data/model_c.obj')">C</button>
        <button class="btn btn-primary w-100" onclick="loadModel('../data/model_d.obj')">D</button>
        <button class="btn btn-primary w-100" onclick="loadModel('../data/model_e.obj')">E</button>
    </div>
  <div id="viewer3d" class="mt-3" style="width: 100%; height: 500px; border: 1px solid #ccc;"></div>
</div>


<!-- Citation -->
<div class="container mt-5">
  <h4>Citation</h4>
  <div id="citation">
@inproceedings{Grethen2025StereoLunar,<br>
&nbsp;&nbsp;title={Adapting Stereo Vision From Objects to 3D Lunar Surface Reconstruction with the StereoLunar Dataset},<br>
&nbsp;&nbsp;author={Clémentine Grethen and Simone Gasparini and Géraldine Morin and Jérémy Lebreton and Lucas Marti and Manuel Sanchez-Gestido},<br>
&nbsp;&nbsp;booktitle={Proceedings of the ICCV Workshop on From Street to Space},<br>
&nbsp;&nbsp;year={2025}<br>
}
  </div>
  <div class="text-center mt-3">
    <button class="copy-button" onclick="copyTextToClipboard()">Copy Citation</button>
  </div>
</div>
<!-- -------------------------------------------------------------------------------------------- -->
<!-- -------------------------------------------------------------------------------------------- -->
<!-- -------------------------------------------------------------------------------------------- -->
<!-- -------------------------------------------------------------------------------------------- -->
<!-- -------------------------------------------------------------------------------------------- -->
<!-- Script for copy -->
<!-- Script for copy -->
<script>
function copyTextToClipboard() {
  const text = document.getElementById('citation').innerText;
  // Use document.execCommand for broader compatibility in iframes
  const textArea = document.createElement("textarea");
  textArea.value = text;
  document.body.appendChild(textArea);
  textArea.select();
  try {
    document.execCommand('copy');
    // Using a custom message box instead of alert()
    displayMessageBox("Citation copied to clipboard!");
  } catch (err) {
    console.error('Failed to copy text: ', err);
    displayMessageBox("Failed to copy citation. Please try again manually.");
  }
  document.body.removeChild(textArea);
}

// Custom message box function
function displayMessageBox(message) {
  const messageBox = document.createElement('div');
  messageBox.style.cssText = `
    position: fixed;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    background-color: #333;
    color: white;
    padding: 15px 25px;
    border-radius: 8px;
    box-shadow: 0 5px 15px rgba(0,0,0,0.3);
    z-index: 1000;
    font-family: 'Arial', sans-serif;
    font-size: 1rem;
    opacity: 0;
    transition: opacity 0.5s ease-in-out;
  `;
  messageBox.textContent = message;
  document.body.appendChild(messageBox);

  // Fade in
  setTimeout(() => {
    messageBox.style.opacity = 1;
  }, 10);

  // Fade out and remove after 3 seconds
  setTimeout(() => {
    messageBox.style.opacity = 0;
    messageBox.addEventListener('transitionend', () => messageBox.remove());
  }, 3000);
}
</script>

<!-- Script for copy -->
<script>
function copyTextToClipboard() {
  const text = document.getElementById('citation').innerText;
  // Use document.execCommand for broader compatibility in iframes
  const textArea = document.createElement("textarea");
  textArea.value = text;
  document.body.appendChild(textArea);
  textArea.select();
  try {
    document.execCommand('copy');
    // Using a custom message box instead of alert()
    displayMessageBox("Citation copied to clipboard!");
  } catch (err) {
    console.error('Failed to copy text: ', err);
    displayMessageBox("Failed to copy citation. Please try again manually.");
  }
  document.body.removeChild(textArea);
}

// Custom message box function
function displayMessageBox(message) {
  const messageBox = document.createElement('div');
  messageBox.style.cssText = `
    position: fixed;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    background-color: #333;
    color: white;
    padding: 15px 25px;
    border-radius: 8px;
    box-shadow: 0 5px 15px rgba(0,0,0,0.3);
    z-index: 1000;
    font-family: 'Arial', sans-serif;
    font-size: 1rem;
    opacity: 0;
    transition: opacity 0.5s ease-in-out;
  `;
  messageBox.textContent = message;
  document.body.appendChild(messageBox);

  // Fade in
  setTimeout(() => {
    messageBox.style.opacity = 1;
  }, 10);

  // Fade out and remove after 3 seconds
  setTimeout(() => {
    messageBox.style.opacity = 0;
    messageBox.addEventListener('transitionend', () => messageBox.remove());
  }, 3000);
}
</script>

<script type="module">
  import * as THREE from "https://esm.run/three@0.152.2";
  import { OBJLoader } from "https://esm.run/three@0.152.2/examples/jsm/loaders/OBJLoader.js";
  import { OrbitControls } from "https://esm.run/three@0.152.2/examples/jsm/controls/OrbitControls.js";

  let scene, camera, renderer, loader, model, controls;
  let defaultMaterial;

  function initViewer() {
    const viewer = document.getElementById('viewer3d');
    scene = new THREE.Scene();
    scene.background = new THREE.Color(0xffffff);

    const ambientLight = new THREE.AmbientLight(0x404040, 2);
    scene.add(ambientLight);

    const directionalLight = new THREE.DirectionalLight(0xffffff, 1);
    directionalLight.position.set(1, 1, 1).normalize();
    scene.add(directionalLight);

    camera = new THREE.PerspectiveCamera(60, viewer.clientWidth / viewer.clientHeight, 0.01, 10000);
    camera.position.set(0, 0, 2);

    renderer = new THREE.WebGLRenderer({ antialias: true });
    renderer.setSize(viewer.clientWidth, viewer.clientHeight);
    viewer.appendChild(renderer.domElement);

    controls = new OrbitControls(camera, renderer.domElement);
    controls.enableDamping = true;
    controls.dampingFactor = 0.05;
    controls.screenSpacePanning = false;
    controls.minDistance = 0.5;
    controls.maxDistance = 10;
    // Removed: controls.maxPolarAngle = Math.PI / 2; // This line restricted vertical rotation

    loader = new OBJLoader();
    defaultMaterial = new THREE.MeshStandardMaterial({ color: 0x007bff, metalness: 0.2, roughness: 0.8 });

    window.addEventListener('resize', onWindowResize);

    animate();

    // Load the default model using the correct raw.githubusercontent.com URL
    loadModel('https://raw.githubusercontent.com/PelissierCombescure/PelissierCombescure.github.io/main/graphics/visapp/3d/gorgoile/sommets_visibles_centered.obj');
  }

  function onWindowResize() {
    const viewer = document.getElementById('viewer3d');
    camera.aspect = viewer.clientWidth / viewer.clientHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(viewer.clientWidth, viewer.clientHeight);
  }

  function loadModel(objFile) {
    if (model) {
      scene.remove(model);
      model.traverse(function (child) {
        if (child.isMesh) {
          child.geometry.dispose();
          if (child.material.isMaterial) {
            child.material.dispose();
          } else if (Array.isArray(child.material)) {
            for (const material of child.material) material.dispose();
          }
        }
      });
    }

    const viewer = document.getElementById('viewer3d');
    viewer.style.backgroundImage = 'url("https://placehold.co/100x100/007bff/ffffff?text=Loading...")';
    viewer.style.backgroundRepeat = 'no-repeat';
    viewer.style.backgroundPosition = 'center';

    loader.load(
      objFile,
      function (object) {
        viewer.style.backgroundImage = 'none';

        object.traverse(function (child) {
          if (child.isMesh) {
            if (!child.material || (Array.isArray(child.material) && child.material.length === 0)) {
              child.material = defaultMaterial;
            }
          }
        });

        const box = new THREE.Box3().setFromObject(object);
        const center = box.getCenter(new THREE.Vector3());
        const size = box.getSize(new THREE.Vector3());

        const maxDim = Math.max(size.x, size.y, size.z);
        const scaleFactor = 1.0 / maxDim;
        object.scale.set(scaleFactor, scaleFactor, scaleFactor);

        const scaledBox = new THREE.Box3().setFromObject(object);
        const scaledCenter = scaledBox.getCenter(new THREE.Vector3());

        object.position.sub(scaledCenter);

        model = object;
        scene.add(model);

        camera.position.set(0, 0, 2);
        controls.target.set(0, 0, 0);
        controls.update();
      },
      function (xhr) {
        console.log((xhr.loaded / xhr.total * 100) + '% loaded');
      },
      function (error) {
        console.error('An error happened loading the OBJ file:', error);
        viewer.style.backgroundImage = 'none';
        displayMessageBox("Error loading 3D model. Check console for details.");
      }
    );
  }

  function animate() {
    requestAnimationFrame(animate);
    controls.update();
    renderer.render(scene, camera);
  }

  window.addEventListener('load', initViewer);
  window.loadModel = loadModel;
</script>

</body>
</html>
